---
title: Глава 3. Функциональные компоненты ОСРВ Azure ThreadX
description: В этой главе описывается высокопроизводительное ядро ОСРВ Azure ThreadX с точки зрения функциональности.
author: philmea
ms.author: philmea
ms.date: 05/19/2020
ms.topic: article
ms.service: rtos
ms.openlocfilehash: aa66ad392171958e5d2cc765992fd1a9e41250a6
ms.sourcegitcommit: e3d42e1f2920ec9cb002634b542bc20754f9544e
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/22/2021
ms.locfileid: "104815635"
---
# <a name="chapter-3---functional-components-of-azure-rtos-threadx"></a>Глава 3. Функциональные компоненты ОСРВ Azure ThreadX

В этой главе описывается высокопроизводительное ядро ОСРВ Azure ThreadX с точки зрения функциональности. Каждый функциональный компонент представлен простым и понятным способом.

## <a name="execution-overview"></a>Общие сведения о выполнении

В приложении ThreadX существуют четыре типа выполнения программы: инициализация, выполнение потока, подпрограммы обработки прерываний (ISR) и таймеры приложения.

На рисунке 2 показаны типы выполнения программы. Более подробные сведения о каждом из этих типов приведены в последующих разделах этой главы.

### <a name="initialization"></a>Инициализация

Как предполагает название, это первый тип выполнения программы в приложении ThreadX. Инициализация включает в себя все выполнение программы между сбросом процессора и точкой входа *цикла планирования потоков*.

### <a name="thread-execution"></a>Выполнение потока

После завершения инициализации ThreadX входит в цикл планирования потоков. Цикл планирования выполняет поиск потока приложения, готового к выполнению. При обнаружении готового потока ThreadX передает ему управление. По завершении потока (или при готовности другого потока с более высоким приоритетом) выполнение передается обратно в цикл планирования потоков, чтобы найти следующий готовый к выполнению высокоприоритетный поток.

Этот процесс непрерывного выполнения и планирования потоков — наиболее распространенный тип выполнения программы в приложениях ThreadX.

### <a name="interrupt-service-routines-isr"></a>Подпрограммы обработки прерываний (ISR)

Прерывания — это основной механизм в системах реального времени. Без прерываний было бы очень сложно своевременно реагировать на изменения во внешнем мире. При обнаружении прерывания процессор сохраняет ключевые сведения о текущем выполнении программы (обычно в стеке), а затем передает управление предопределенной области программы. Эта предопределенная область программы обычно называется подпрограммой обработки прерываний. В большинстве случаев прерывания происходят во время выполнения потока (или в цикле планирования потоков). Однако прерывания могут также возникать внутри выполняемой подпрограммы ISR или таймера приложения.

![Типы выполнения программы](./media/user-guide/types-program-execution.png)

**РИСУНОК 2. Типы выполнения программы**

### <a name="application-timers"></a>Таймеры приложения

Таймеры приложения похожи на подпрограммы ISR, за исключением того, что их аппаратная реализация (обычно используется одно периодическое аппаратное прерывание) скрыта от приложения. Такие таймеры используются приложениями для прерывания при истечении времени ожидания, периодического выполнения и (или) запуска служб наблюдения. Как и в случае с подпрограммами ISR, таймеры приложения чаще всего прерывают выполнение потоков. Однако в отличие от ISR таймеры приложения не могут прерывать друг друга.

## <a name="memory-usage"></a>Использование памяти

ThreadX размещается в памяти вместе с прикладной программой. В результате использование статической памяти (или фиксированной памяти) в ThreadX зависит от используемых инструментов разработки (например, компилятора, компоновщика и указателя). Использование динамической памяти (или памяти во время выполнения) контролируется непосредственно приложением.

### <a name="static-memory-usage"></a>Использование статической памяти

Большинство инструментов разработки разделяют образ прикладной программы на пять основных областей: *инструкции*, *константы*, *инициализированные данные*, *неинициализированные данные* и *системный стек*. На рисунке 3 показан пример этих областей памяти.

Важно учитывать, что это только пример. Структура фактической статической памяти зависит от используемых процессора, инструментов разработки и базового оборудования.

В области инструкций содержатся все инструкции процессора для программы. Эта область обычно является самой крупной и часто размещается в ПЗУ.

Область констант содержит различные скомпилированные константы, включая строки, определения которых или ссылки на которые указаны в программе. Кроме того, эта область содержит "начальную копию" области инициализированных данных. В процессе инициализации в компиляторе для *использования памяти* эта часть области констант используется для настройки инициализированных данных в ОЗУ. Область констант обычно следует за областью инструкций и часто размещается в ПЗУ.

Области инициализированных и неинициализированных данных содержат все глобальные и статические переменные. Эти области всегда размещаются в ОЗУ.

Системный стек обычно настраивается сразу после областей инициализированных и неинициализированных данных.

Системный стек используется компилятором во время инициализации, а затем — системой ThreadX во время инициализации, после чего применяется при обработке ISR.

![Пример области памяти](./media/user-guide/memory-area-example.png)

**РИСУНОК 3. Пример области памяти**

### <a name="dynamic-memory-usage"></a>Использование динамической памяти

Как упоминалось ранее, использование динамической памяти контролируется непосредственно приложением. Блоки управления и области памяти, связанные со стеками, очередями и пулами памяти, можно разместить в любом месте в области памяти на целевом оборудовании. Это важная возможность, так как она упрощает использование различных типов физической памяти.

Например, предположим, что целевая аппаратная среда использует как быстродействующую, так и медленнодействующую память. Если приложению требуется дополнительная производительность для обработки потока с высоким приоритетом, его блок управления (TX_THREAD) и стек можно поместить в область быстродействующей памяти, что может значительно повысить производительность.

## <a name="initialization"></a>Инициализация

Важно понимать, как происходит процесс инициализации. В ходе его выполнения настраивается начальная аппаратная среда. Кроме того, при инициализации приложение получает свои начальные параметры.

> [!NOTE]
> *ThreadX пытается использовать (по возможности) полный процесс инициализации инструмента разработки. Это упрощает обновление до новых версий инструментов разработки в будущем.*

### <a name="system-reset-vector"></a>Вектор сброса системы

Все микропроцессоры имеют логику сброса. Когда происходит сброс (аппаратный или программный), адрес точки входа приложения извлекается из определенного расположения в памяти. После получения точки входа процессор передает управление в это расположение. Точка входа приложения довольно часто программируется на языке ассемблера и обычно предоставляется инструментами разработки (по крайней мере в виде шаблона). В некоторых случаях в ThreadX предоставляется специальная версия программы входа.

### <a name="development-tool-initialization"></a>Инициализация инструментов разработки

После завершения инициализации низкого уровня управление передается инструменту разработки для инициализации высокого уровня. Обычно на этом этапе настраиваются инициализированные глобальные и статические переменные C. Напомним, что их исходные значения извлекаются из области констант. Особенности инициализации зависят от конкретного инструмента разработки.

### <a name="main-function"></a>Функция main

После завершения инициализации инструмента разработки управление передается в функцию *main*, предоставляемую пользователем. На этом этапе приложение определяет, что произойдет дальше. Для большинства приложений функция main просто вызывает функцию *tx_kernel_enter*, которая выполняет вход в ThreadX. Однако перед входом в ThreadX приложения могут выполнять предварительную обработку (обычно для инициализации оборудования).

> [!IMPORTANT]
> *Вызов tx_kernel_enter не возвращает управление, поэтому обработка после него не выполняется.*

### <a name="tx_kernel_enter"></a>tx_kernel_enter

Функция входа координирует инициализацию различных внутренних структур данных ThreadX, а затем вызывает функцию определения приложения, ***tx_application_define***.

Когда функция ***tx_application_define*** возвращает результат, управление передается в цикл планирования потоков. Это свидетельствует о завершении инициализации.

### <a name="application-definition-function"></a>Функция определения приложения

Функция ***tx_application_define*** определяет все начальные потоки, очереди, семафоры, мьютексы, флаги событий, пулы памяти и таймеры приложения. Можно также создавать и удалять ресурсы системы из потоков во время нормальной работы приложения. Однако все начальные ресурсы приложения определяются этой функцией.

Функция **tx_application_define** имеет один входной параметр, о котором, безусловно, стоит упомянуть. Единственным входным параметром этой функции является адрес ОЗУ _first-available*. Обычно он используется в качестве отправной точки при начальном выделении памяти среды выполнения для стеков потоков, очередей и пулов памяти.

> [!NOTE]
> *После завершения инициализации только выполняющийся поток может создавать и удалять системные ресурсы, включая другие потоки. Поэтому во время инициализации необходимо создать хотя бы один поток.*

### <a name="interrupts"></a>Прерывания

Прерывания остаются отключенными в ходе всего процесса инициализации. Если приложение каким-либо образом включит прерывания, это может привести к непредсказуемому поведению. На рисунке 4 показан весь процесс инициализации — от сброса системы до инициализации конкретного приложения.

## <a name="thread-execution"></a>Выполнение потока

Планирование и выполнение потоков приложения — наиболее важная задача ThreadX. Поток обычно определяется в виде частично независимого сегмента программы с конкретной целью. Объединенная обработка всех потоков формирует приложение.

Потоки создаются динамически путем вызова функции ***tx_thread_create** _ во время инициализации или выполнения потока. Потоки создаются в состоянии готовности (_ready*) или *приостановки*.

![Процесс инициализации](./media/user-guide/initialization-process.png)

**РИСУНОК 4. Процесс инициализации**

### <a name="thread-execution-states"></a>Состояния выполнения потока

Понимание различных состояний обработки потоков играет ключевую роль для понимания всей многопоточной среды. В ThreadX используются пять отдельных состояний потока: *готов*, *приостановлен*, *выполняется*, *завершен* и *выполнен*. На рисунке 5 показана схема перехода состояния потока в ThreadX.

![Переход состояния потока](./media/user-guide/thread-state-transition.png)

**РИСУНОК 5. Переход состояния потока**

Поток находится в состоянии *готов*, когда он готов к выполнению. Готовый поток не выполняется, пока не станет потоком с наивысшим приоритетом в состоянии готовности. В этом случае ThreadX его выполняет и он переходит в состояние *выполняется*.

Если поток с более высоким приоритетом перейдет в состояние готовности, выполняющийся поток вернется в состояние *готов*. Затем будет выполнен новый готовый поток с высоким приоритетом, который перейдет в логическое состояние *выполняется*. Переход между состоянием *готов* и *выполняется* происходит при каждом вытеснении потока.

В определенный момент времени в состоянии *выполняется* может находиться только один поток. Это происходит потому, что поток в состоянии *выполняется* управляет базовым процессором.

Потоки в состоянии *приостановлен* не могут быть выполнены. Причинами перехода в состояние *приостановлен* могут быть временная приостановка, сообщения очереди, семафоры, мьютексы, флаги событий, память и приостановка основного потока. После устранения причины приостановки поток возвращается в состояние *готов*.

Поток в состоянии *выполнен* — это поток, который завершил обработку и возвратил результат из своей функции входа. Функция входа указывается во время создания потока. Поток в состоянии *выполнен* не может быть выполнен повторно.

Поток находится в состоянии *завершен*, если он сам или другой поток вызвал службу *tx_thread_terminate*. Поток в состоянии *завершен* не может быть выполнен повторно.

> [!IMPORTANT]
> *Если требуется перезапустить выполненный или завершенный поток, приложение должно сначала удалить поток. Затем его можно повторно создать и повторно запустить.*

### <a name="thread-entryexit-notification"></a>Уведомление о входе и выходе в потоке

Некоторые приложения могут отправлять уведомления о том, что определенный поток выполнил вход в первый раз, был выполнен или завершен. ThreadX обеспечивает эту возможность с помощью службы ***tx_thread_entry_exit_notify***. Эта служба регистрирует функцию уведомления приложения для определенного потока, которая вызывается ThreadX всякий раз, когда этот поток начал выполнение, выполнен или завершен. После вызова функция уведомления приложения может выполнить специализированную обработку для приложения. Обычно это подразумевает информирование другого потока приложения о событии с помощью примитива синхронизации ThreadX.

### <a name="thread-priorities"></a>Приоритеты потоков

Как было сказано ранее, поток — это частично независимый сегмент программы с определенной целью. Однако потоки не идентичны с точки зрения приоритетности задач, которые они выполняют. Одни потоки гораздо важнее других. Такая разная важность потоков присуща внедренным приложениям реального времени.

ThreadX определяет важность потока при создании, назначая ему числовое значение *приоритета*. В ThreadX можно настроить максимальное число приоритетов от 32 до 1024 с шагом 32. Фактическое максимальное число приоритетов определяется константой **TX_MAX_PRIORITIES** во время компиляции библиотеки ThreadX. Наличие большего количества приоритетов не приводит к значительному увеличению временных затрат на обработку. Однако для управления каждой группой из 32 уровней приоритета требуются дополнительные 128 байтов ОЗУ. Например, для 32 уровней приоритета требуются 128 байтов ОЗУ, для 64 уровней приоритета — 256 байтов ОЗУ, а для 96 уровней приоритета — 384 байта ОЗУ.

По умолчанию ThreadX использует 32 уровня приоритета, от 0 до 31. Чем ниже числовое значение, тем выше приоритет. Таким образом, приоритет 0 наивысший, а приоритет (**TX_MAX_PRIORITIES**–1) самый низкий.

Несколько потоков могут иметь одинаковый приоритет при совместном планировании или использовании временных срезов. Кроме того, приоритеты потоков можно изменить во время выполнения.

### <a name="thread-scheduling"></a>Планирование потоков

ThreadX планирует потоки в зависимости от их приоритета. Сначала выполняется готовый поток с наивысшим приоритетом. Если готово несколько потоков с одинаковым приоритетом, они выполняются по принципу *первым поступил — первым обслужен* (FIFO).

### <a name="round-robin-scheduling"></a>Планирование с использованием циклического перебора

ThreadX поддерживает планирование с *циклическим перебором* нескольких потоков, имеющих одинаковый приоритет. Для этого используются совместные вызовы службы ***tx_thread_relinquish** _. Эта служба предоставляет всем другим готовым потокам с таким же приоритетом возможность выполнения, прежде чем снова будет выполнена вызывающая служба _ *_tx_thread_relinquish_**.

### <a name="time-slicing"></a>Временные срезы

*Временные срезы* — это еще один тип планирования с циклическим перебором. Временной срез определяет максимальное количество тактов таймера (прерываний таймера), которые поток может выполнять, не отдавая управление процессором. В ThreadX временные срезы задаются отдельно для каждого потока. Временной срез потока назначается во время создания и может быть изменен во время выполнения. По истечении срока действия временного среза все остальные готовые потоки с таким же уровнем приоритета получают шанс выполнения до того, как этот поток с временным срезом будет выполнен повторно.

После приостановки или освобождения потока, вызова им службы ThreadX для вытеснения, а также после того, как поток сам изменит свой временной срез, ему назначается новый временной срез.

Если поток с временным срезом будет вытеснен, он возобновится до других готовых потоков с таким же приоритетом и будет выполняться оставшуюся часть своего временного среза.

> [!NOTE]
> *Использование временного среза приводит к незначительным системным издержкам. Так как временной срез полезен только в случаях, когда несколько потоков имеют одинаковый приоритет, его не следует назначать потокам с уникальными приоритетами.*

### <a name="preemption"></a>Вытеснение

Вытеснение — это процесс временного прерывания выполнения потока в пользу потока с более высоким приоритетом. Этот процесс невидим для выполняющегося потока. После выполнения потока с более высоким приоритетом управление возвращается именно тому потоку, на котором произошло вытеснение. Это очень важная функция в системах реального времени, так как она упрощает быстрое реагирование на важные события приложений. Хотя это очень важная функция, вытеснение может также быть источником различных проблем, включая нехватку ресурсов, чрезмерную нагрузку и инверсию приоритета.

### <a name="preemption-thresholdtrade"></a>Возможность Preemption Threshold&trade;

Чтобы устранить некоторые проблемы, связанные с вытеснением, ThreadX предоставляет уникальную расширенную возможность, называемую *preemption-threshold* (порог вытеснения).

Порог вытеснения позволяет потоку указать *порог* приоритета для отключения вытеснения. Потоки, имеющие приоритет выше этого порога, по-прежнему могут быть вытеснены, а потоки, приоритет которых ниже данного порога, не вытесняются.

Например, предположим, что поток с приоритетом 20 взаимодействует с группой потоков, имеющих приоритеты от 15 до 20. При выполнении критических разделов поток с приоритетом 20 может установить порог вытеснения, равный 15, тем самым предотвращая вытеснение любыми потоками, с которыми он взаимодействует. Очень важные потоки (с приоритетом от 0 до 14) по-прежнему смогут вытеснить этот поток во время обработки его критических разделов, что обеспечит более адаптивную обработку.

Разумеется, поток может отключить любое вытеснение, установив порог вытеснения, равный 0. Кроме того, порог вытеснения можно изменить во время выполнения.

> [!NOTE]
> *При использовании порога вытеснения отключаются временные срезы для указанного потока.*

### <a name="priority-inheritance"></a>Наследование приоритетов

ThreadX также поддерживает необязательное наследование приоритета в своих службах мьютексов, описанное далее в этой главе. Наследование приоритета позволяет потоку с более низким приоритетом временно принять приоритет потока с более высоким приоритетом, который ожидает мьютекс, принадлежащий к потоку с более низким приоритетом. Эта возможность позволяет приложению избежать недетерминированной инверсии приоритета, устраняя вытеснение потоков с промежуточным приоритетом. Конечно, для получения аналогичного результата можно использовать *порог вытеснения*.

### <a name="thread-creation"></a>Создание потока

Потоки приложения создаются во время инициализации или во время выполнения других потоков приложения. Количество потоков, которые может создать приложение, не ограничено.

### <a name="thread-control-block-tx_thread"></a>TX_THREAD: блок управления потока

Характеристики каждого потока содержатся в его блоке управления. Эта структура определена в файле ***tx_api.h***.

Блок управления потока может размещаться в любом месте в памяти, но чаще всего он определяется вне области какой-либо функции, благодаря чему функционирует как глобальная структура.

Поиск блока управления в других областях требует больших усилий, как и в любой динамически выделяемой памяти. Если блок управления выделяется в функции C, то связанная с ним память является частью стека вызывающего потока. Как правило, не следует использовать локальное хранилище для блоков управления, так как после того, как функция возвратит результат, все пространство его стека локальных переменных освобождается, независимо от того, используется ли оно другим потоком для блока управления.

В большинстве случаев приложение игнорирует содержимое блока управления потока. Однако в некоторых ситуациях, особенно при отладке, полезно изучить определенные элементы. Ниже приведены некоторые из наиболее полезных элементов блока управления.

**tx_thread_run_count**: содержит счетчик запланированных выполнений потока. Если значение счетчика увеличилось, это означает, что поток запланирован и выполняется.

**tx_thread_state**: содержит состояние связанного потока. Ниже перечислены возможные состояния потока.

|  Состояние потока   | Значение |
| --------------- | ------ |
| TX_READY       | (0x00) |
| TX_COMPLETED   | (0x01) |
| TX_TERMINATED  | (0x02) |
| TX_SUSPENDED   | (0x03) |
| TX_SLEEP       | (0x04) |
| TX_QUEUE_SUSP | (0x05) |
| TX_SEMAPHORE_SUSP | (0x06) |
| TX_EVENT_FLAG   | (0x07) |
| TX_BLOCK_MEMORY | (0x08) |
| TX_BYTE_MEMORY  | (0x09) |
| TX_MUTEX_SUSP   | (0x0D) |

> [!NOTE]
> *Конечно, в блоке управления потока существует множество других интересных полей, включая указатель на стек, значение временного среза, приоритеты и т. д. Пользователи могут просматривать элементы блока управления, но изменять их строго запрещено!*

> [!IMPORTANT]
> *В этом разделе нет эквивалента для состояния "выполняется", упомянутого ранее. Это необязательно, поскольку в данный момент времени существует только один исполняемый поток. Состояние выполнения потока также* **TX_READY**.

### <a name="currently-executing-thread"></a>Текущий выполняемый поток

Как упоминалось ранее, в любой заданный момент времени может выполняться только один поток. Существует несколько способов определения выполняемого потока. Они зависят от того, какой поток делает запрос.
Сегмент программы может получить адрес блока управления выполняемого потока, вызвав службу ***tx_thread_identify***. Это удобно использовать в общих фрагментах кода приложения, которые выполняются в нескольких потоках.

Во время сеансов отладки пользователи могут изучить внутренний указатель ThreadX ***_tx_thread_current_ptr***. Он содержит адрес блока управления текущего выполняемого потока. Если этот указатель равен NULL, то потоки приложения не выполняются, т. е. ThreadX во время цикла планирования ожидает, когда какой-либо поток станет готовым.

### <a name="thread-stack-area"></a>Область стека потока

Каждый поток должен иметь собственный стек для сохранения контекста последнего выполнения и использования компилятором. Большинство компиляторов C использует стек для выполнения вызовов функций и временного выделения локальных переменных. На рисунке 6 показан типичный стек потока.

Область памяти, в которой размещается стек потока, выбирает приложение. Область стека указывается во время создания потока и может размещаться в любом месте адресного пространства целевого оборудования. Это важная функция, так как она позволяет приложениям повысить производительность важных потоков, помещая их стек в высокоскоростную оперативную память.

**Область памяти стека** (пример)

![Типичный стек потоков](./media/user-guide/typical-thread-stack.png)

**РИСУНОК 6. Типичный стек потока**

Можно сказать, что вопрос о размере стека — один из наиболее часто задаваемых вопросов о потоках. Область стека потока должна быть достаточно большой, чтобы обеспечить вложенность вызова функций в наиболее неблагоприятном случае, выделение локальных переменных и сохранение контекста последнего выполнения этого потока.

Минимальный размер стека, **TX_MINIMUM_STACK**, определяет ThreadX. Стек этого размера поддерживает сохранение контекста потока, минимальное количество вызовов функций и выделение локальных переменных.

Однако для большинства потоков минимальный размер стека недостаточен, и пользователь должен проверить требование размера для наиболее неблагоприятного случая, проверив вложенность вызова функций и выделение локальных переменных. Конечно, всегда лучше начать с более крупной области стека.

Если объем памяти ограничен, размер стека потока можно будет точно настроить после отладки приложения. Прежде чем создавать потоки, предпочтительно заранее задать все области стека, используя легко идентифицируемый шаблон данных, например (0xEFEF). После тщательной проверки приложения можно будет изучить области стека, чтобы узнать, какой объем стека фактически использовался. Для этого можно выполнить поиск области стека, в которой шаблон данных остался неизменным. На рисунке 7 показана предварительная установка для стека значения 0xEFEF после обстоятельного выполнения потока.

**Область памяти стека** (другой пример)

![Предварительная установка для стека значения 0xEFEF*](./media/user-guide/stack-preset.png)

**РИСУНОК 7. Предварительная установка для стека значения 0xEFEF**

> [!IMPORTANT]
> *По умолчанию ThreadX инициализирует каждый байт каждого стека потока, используя значение 0xEF.*

### <a name="memory-pitfalls"></a>Проблемы с памятью

Требования к стеку для потоков могут быть высокими. Поэтому важно разработать приложение, использующее разумное количество потоков. Более того, необходимо уделить внимание тому, чтобы избежать чрезмерного использования стека в потоках. Следует избегать рекурсивных алгоритмов и больших локальных структур данных.

В большинстве случаев переполнение стека приводит к тому, что выполнение потока повреждает область памяти, смежную с его областью стека (обычно повреждается область перед стеком потока). Результаты могут быть непредсказуемыми, но чаще всего это приводит к необычному изменению счетчика программы. Это часто называют "залезать в дебри". Разумеется, единственный способ избежать этого — обеспечить достаточный размер всех стеков потоков.

### <a name="optional-run-time-stack-checking"></a>Дополнительная проверка стека во время выполнения

ThreadX позволяет проверять стек каждого потока на наличие повреждений во время выполнения. По умолчанию ThreadX заполняет каждый байт создаваемых стеков потоков шаблоном данных 0xEF. Если приложение создает библиотеку ThreadX с определенным параметром **TX_ENABLE_STACK_CHECKING**, ThreadX будет анализировать стек каждого потока на наличие повреждений, когда его выполнение будет приостанавливаться или возобновляться. При обнаружении повреждения стека ThreadX вызовет подпрограмму обработки ошибок стека приложения, указанную в вызове **_tx_thread_stack_error_notify_ *_. В противном случае, если не был указан обработчик ошибок стека, ThreadX вызовет внутреннюю подпрограмму _* _ _tx_thread_stack_error_handler_**.

### <a name="reentrancy"></a>Повторный вход

Одним из реальных преимуществ многопоточности является то, что одна и та же функция C может быть вызвана из нескольких потоков. Это дает широкие возможности, а также сокращает объем кода. Однако для этого требуется, чтобы функции C, вызываемые из нескольких потоков, были *реентерабельными*.

В сущности, реентерабельная функция сохраняет адрес возвращения вызывающего объекта в текущем стеке и не использует глобальные или статические переменные C, которые были настроены ранее. Большинство компиляторов помещает адрес возвращения в стек. Следовательно, разработчикам приложений остается только позаботиться об использовании *глобальных* и *статических* переменных.

Примером функции, не являющейся реентерабельной, является функция строкового маркера ***strtok***, доступная в стандартной библиотеке C. Эта функция "запоминает" указатель на предыдущую строку при последующих вызовах. Для этого она использует статический указатель на строку. Если эта функция будет вызвана из нескольких потоков, скорее всего, будет возвращен недопустимый указатель.

### <a name="thread-priority-pitfalls"></a>Проблемы, связанные с приоритетами потоков

Выбор приоритетов потоков является одним из наиболее важных аспектов многопоточности. Иногда назначение приоритетов на основе кажущейся важности потока без определения того, что именно требуется во время выполнения, выглядит очень заманчиво. Неправильное назначение приоритетов потоков может привести к нехватке ресурсов для потоков, породить инверсию приоритета, уменьшить пропускную способность обработки и привести к тому, что поведение приложения во время выполнения будет сложно понять.

Как упоминалось ранее, ThreadX предоставляет алгоритм планирования с вытеснением на основе приоритета. Потоки с низким приоритетом не выполняются до тех пор, пока не останется ни одного готового к выполнению потока с более высоким приоритетом. Если поток с более высоким приоритетом всегда готов, потоки с низким приоритетом никогда не выполнятся. Это состояние называется *нехваткой ресурсов потоков*.

Большинство проблем, связанных с нехваткой ресурсов потоков, обнаруживается на ранних этапах отладки и могут быть устранены. Для этого нужно сделать так, чтобы выполнение потоков с более высоким приоритетом не было непрерывным. Кроме того, можно добавить в приложение логику, которая постепенно повышает приоритет потоков, испытывающих нехватку ресурсов, пока они не получат шанс на выполнение.

Еще одной проблемой, связанной с приоритетами потоков, является *инверсия приоритета*. Она происходит, когда поток с более высоким приоритетом приостанавливается из-за того, что требуемый ему ресурс используется потоком с более низким приоритетом. Конечно, в некоторых случаях нужно, чтобы два потока с разными приоритетами совместно использовали общий ресурс. Если активны только эти потоки, то время инверсии приоритета ограничено периодом, в течение которого поток с низким приоритетом владеет ресурсом. Такая ситуация детерминирована и вполне приемлема. Однако если в случае инверсии приоритета становятся активными потоки с промежуточным приоритетом, то время инверсии приоритета больше не является детерминированным и может привести к сбою приложения.

Существуют три принципиально разных метода предотвращения недетерминированной инверсии приоритета в ThreadX. Во-первых, назначение приоритетов и поведение во время выполнения в приложении можно спроектировать таким образом, чтобы не возникала проблема с инверсией приоритета. Во-вторых, для потоков с низким приоритетом можно использовать *порог вытеснения*, чтобы блокировать их вытеснение промежуточными потоками, пока они используют ресурсы совместно с потоками с более высоким приоритетом. Наконец, для потоков, использующих объекты мьютексов ThreadX для защиты системных ресурсов, можно устранить недетерминированную инверсию приоритета с помощью необязательного *наследования приоритета* мьютекса.

### <a name="priority-overhead"></a>Временные затраты из-за приоритетов

Одним из наиболее упускаемых из виду способов снижения временных затрат на многопоточность является сокращение переключений контекста. Как упоминалось выше, переключение контекста происходит, когда выполнение потока с более высоким приоритетом оказывается предпочтительнее выполнения текущего потока. Стоит упомянуть, что потоки с более высоким приоритетом могут оказаться готовыми к работе как в результате внешних событий (например, прерываний), так и вследствие вызовов служб выполняемым потоком.

Чтобы проиллюстрировать влияние приоритетов потоков на временные затраты из-за переключения контекста, предположим, что существуют три среды потоков с потоками *thread_1*, *thread_2* и *thread_3*. Предположим, что все эти потоки находятся в состоянии приостановки и ожидают сообщения. Когда поток thread_1 получает сообщение, он немедленно пересылает его потоку thread_2. Затем поток thread_2 пересылает это сообщение потоку thread_3. Поток thread_3 просто отклоняет сообщение. После того как каждый поток обработал сообщение, он возвращается и ожидает другое сообщение.

Обработка, необходимая для выполнения этих трех потоков, сильно зависит от их приоритетов. Если все потоки имеют одинаковый приоритет, то перед выполнением каждого потока происходит одно переключение контекста. Переключение контекста происходит, когда каждый поток приостанавливается при пустой очереди сообщений.

Но если у потока thread_2 более высокий приоритет, чем у потока thread_1, а у потока thread_3 более высокий приоритет, чем у потока thread_2, то число переключений контекста удваивается. Это связано с тем, что в службе *tx_queue_send* происходит еще одно переключение контекста, когда она обнаруживает, что поток с более высоким приоритетом уже готов.

Механизм применения порога вытеснения ThreadX позволяет избежать этих дополнительных переключений контекста, не меняя исходные приоритеты. Это важная функция, так как она позволяет использовать несколько приоритетов потоков во время планирования, одновременно устраняя нежелательные переключения контекста между ними во время выполнения потоков.

### <a name="run-time-thread-performance-information"></a>Сведения о производительности потоков во время выполнения

ThreadX предоставляет дополнительные сведения о производительности потоков во время выполнения. Если при сборке приложения и библиотеки ThreadX был определен параметр **TX_THREAD_ENABLE_PERFORMANCE_INFO**, ThreadX собирает следующую информацию.

Общее число (для всей системы):

  - возобновлений потоков;

  - приостановок потоков;

  - вытеснений путем вызова службы;

  - вытеснений путем прерывания;

  - инверсий приоритета;

  - временных срезов;

  - освобождений;

  - превышений времени ожидания потока;

  - прерываний приостановки;

  - возвращений состояния бездействия системы;

  - возвращений состояния системы, отличного от бездействия.

Общее число (для каждого потока):

  - возобновлений;

  - приостановок;

  - вытеснений путем вызова службы;

  - вытеснений путем прерывания;

  - инверсий приоритета;

  - временных срезов;

  - освобождений потока;

  - превышений времени ожидания потока;

  - прерываний приостановки.

Эти сведения можно получить во время выполнения с помощью служб ***tx_thread_performance_info_get** _ и _*_tx_thread_performance_system_info_get_**. С помощью сведений о производительности потоков удобно определять, правильно ли работает приложение. Они также полезны для оптимизации приложения. Например, относительно частое вытеснение путем вызова службы может указывать на слишком низкое значение приоритета потока и (или) порога вытеснения. Более того, относительно редкое возвращение состояния бездействия системы может означать, что потоки с низким приоритетом недостаточно приостанавливаются.

### <a name="debugging-pitfalls"></a>Проблемы при отладке

Отладка многопоточных приложений немного сложнее, так как один программный код может выполняться из нескольких потоков. В таких случаях просто точки останова может быть недостаточно. Отладчик также должен просмотреть текущий указатель на поток **_tx_thread_current_ptr** с помощью условной точки останова, чтобы определить, следует ли отлаживать вызывающий поток.

Большую часть этих функций выполняют пакеты поддержки многопоточности, предлагаемые различными поставщиками инструментов разработки. Благодаря простой структуре ThreadX интегрировать эту систему с различными инструментами разработки относительно легко.

Размер стека всегда играет важную роль при отладке в режиме многопоточности. При обнаружении необъяснимого поведения обычно стоит начать с увеличения размера стека для всех потоков, особенно это касается размера стека последнего выполнявшегося потока.

> [!TIP]
> *Кроме того, рекомендуется создать библиотеку ThreadX с определенным параметром **TX_ENABLE_STACK_CHECKING**. Это поможет как можно раньше изолировать проблемы, связанные с повреждением стека.*

## <a name="message-queues"></a>Очереди сообщений

Очереди сообщений являются основным средством взаимодействия между потоками в ThreadX. В очереди сообщений может находиться одно или несколько сообщений. Очередь сообщений, содержащая одно сообщение, обычно называется *почтовым ящиком*.

Сообщения копируются в очередь службой ***tx_queue_send** _, а из очереди — службой _*_tx_queue_receive_**. Единственным исключением является ситуация, когда поток приостанавливается, ожидая сообщения в пустой очереди. В этом случае следующее сообщение, отправленное в очередь, помещается непосредственно в область назначения потока.

Каждая очередь сообщений является общедоступным ресурсом. В ThreadX нет ограничений на использование очередей сообщений.

### <a name="creating-message-queues"></a>Создание очередей сообщений

Очереди сообщений создаются во время инициализации или во время выполнения потоками приложения. Количество очередей сообщений в приложении не ограничено.

### <a name="message-size"></a>Размер сообщения

Каждая очередь сообщений поддерживает ряд фиксированных размеров сообщений. Доступные размеры сообщений: от 1 до 16 32-разрядных слов включительно. Размер сообщения указывается при создании очереди. Сообщения приложения, размер которых превышает 16 слов, должны передаваться посредством указателя. Для этого создается очередь с размером сообщения в 1 слово (достаточно для хранения указателя), после чего вместо всего сообщения отправляются и принимаются указатели на сообщение.

### <a name="message-queue-capacity"></a>Емкость очереди сообщений

Количество сообщений, которые может хранить очередь, зависит от заданного для нее размера сообщения и области памяти, предоставленной ей во время создания. Общая емкость сообщений в очереди вычисляется путем деления числа байтов в каждом сообщении на общее число байтов в указанной области памяти.

Например, если очередь сообщений, поддерживающая размер сообщения в одно 32-разрядное слово (4 байта), создается для области памяти в 100 байт, то ее емкость составляет 25 сообщений.

### <a name="queue-memory-area"></a>Область памяти очереди

Как упоминалось ранее, область памяти для буферизации сообщений указывается во время создания очереди. Как и в случае с другими областями памяти в ThreadX, она может находиться в любом месте адресного пространства целевого оборудования.

Это важная возможность, так как она обеспечивает значительную гибкость для приложения. Например, приложение может разместить область памяти важной очереди в высокоскоростном ОЗУ для повышения производительности.

### <a name="thread-suspension"></a>Приостановка потока

Потоки приложения могут быть приостановлены при попытке отправить или получить сообщение из очереди. Как правило, приостановка потока предполагает ожидание сообщения из пустой очереди. Однако поток также может быть приостановлен при попытке отправить сообщение в полную очередь.

Когда условие приостановки разрешается, запрошенная служба завершает выполнение и ожидающий поток возобновляется. Если на одной очереди приостанавливается несколько потоков, они возобновляются в том же порядке, в котором были приостановлены (FIFO).

Однако также возможно возобновление по приоритету, если приложение вызовет ***tx_queue_prioritize*** перед вызовом службы очередей, которая прекращает приостановку потоков. Служба назначения приоритетов для очереди помещает поток с наибольшим приоритетом в начало списка приостановки, оставляя прочие приостановленные потоки в том же порядке по принципу FIFO.

Для всех приостановок очередей также доступно прерывание по истечении времени ожидания. По сути, время ожидания задает максимальное число тактов таймера, в которые поток будет оставаться приостановленным. По истечении времени ожидания поток возобновляется и служба возвращает соответствующий код ошибки.

### <a name="queue-send-notification"></a>Уведомление об отправке в очередь

Некоторые приложения могут использовать преимущества уведомлений о каждом добавлении сообщения в очередь. ThreadX обеспечивает эту возможность с помощью службы ***tx_queue_send_notify***. Эта служба регистрирует указанную функцию уведомления приложения для заданной очереди. После чего ThreadX будет вызывать эту функцию уведомления приложения всякий раз, когда в очередь будет отправлено сообщение. Конкретная обработка в функции уведомления приложения определяется самим приложением. Однако обычно она предполагает возобновление соответствующего потока для обработки нового сообщения.

### <a name="queue-event-chainingtrade"></a>Event chaining&trade; для очереди

Возможности уведомлений в ThreadX можно использовать для объединения различных событий синхронизации в цепочку. Обычно это удобно, когда один поток должен обрабатывать несколько событий синхронизации.

Например, предположим, что один поток отвечает за обработку сообщений из пяти разных очередей. При этом он должен приостанавливаться, если нет доступных сообщений. Это легко реализовать, зарегистрировав функцию уведомления приложения для каждой очереди и введя дополнительный семафор со счетчиком. В частности, функция уведомления приложения вызывает службу *tx_semaphore_put* при каждом вызове (значение семафора представляет общее количество сообщений во всех пяти очередях). Поток обработки приостанавливается на этом семафоре с помощью службы *tx_semaphore_get*. Если семафор доступен (в данном случае, когда доступно сообщение), то поток обработки возобновляется. Затем выполняется опрос каждой очереди на наличие сообщения, найденное сообщение обрабатывается и выполняется вызов службы ***tx_semaphore_get*** для ожидания следующего сообщения. Реализовать это без цепочки событий довольно сложно, и, скорее всего, для этого потребуется большее число потоков и (или) дополнительный код приложения.

Как правило, *цепочки событий* позволяют уменьшить количество потоков, временные затраты и требования к ОЗУ. Они также предоставляют очень гибкий механизм для соблюдения требований синхронизации в более сложных системах.

### <a name="run-time-queue-performance-information"></a>Сведения о производительности очередей во время выполнения
ThreadX предоставляет дополнительные сведения о производительности очередей во время выполнения. Если при сборке приложения и библиотеки ThreadX был определен параметр ***TX_QUEUE_ENABLE_PERFORMANCE_INFO***, ThreadX собирает следующую информацию.

Общее число (для всей системы):

  - отправленных сообщений;

  - полученных сообщений;

  - приостановок из-за пустой очереди;

  - приостановок из-за переполнения очереди;

  - возвращенных ошибок из-за переполнения очереди (приостановка не задана);

  - превышений времени ожидания очереди.

Общее число (для каждой очереди):

  - отправленных сообщений;

  - полученных сообщений;

  - приостановок из-за пустой очереди;

  - приостановок из-за переполнения очереди;

  - возвращенных ошибок из-за переполнения очереди (приостановка не задана);

  - превышений времени ожидания очереди.

Эти сведения можно получить во время выполнения с помощью служб ***tx_queue_performance_info_get** _ и _*_tx_queue_performance_system_info_get_**. С помощью сведений о производительности очередей удобно определять, правильно ли работает приложение. Они также полезны для оптимизации приложения. Например, относительно большое число приостановок из-за переполнения очереди позволяет предположить, что следует увеличить размер очереди.

### <a name="queue-control-block-tx_queue"></a>TX_QUEUE: блок управления очереди

Характеристики каждой очереди сообщений находятся в ее блоке управления. Он содержит важные сведения, например количество сообщений в очереди. Эта структура определена в файле ***tx_api.h***.

Блоки управления очереди могут размещаться в любом месте в памяти, но чаще всего они определяются вне области какой-либо функции, благодаря чему функционируют как глобальная структура.

### <a name="message-destination-pitfall"></a>Проблемы с назначением сообщений

Как упоминалось ранее, сообщения копируются между областью очереди и областями данных приложения. Важно убедиться, что область назначения для получаемого сообщения достаточно велика, чтобы вместить все сообщение. В противном случае память, следующая за областью назначения сообщения, скорее всего, будет повреждена.

> [!NOTE]
> *Это особенно фатально, когда область назначения сообщений в стеке слишком мала. В этом случае повреждение обратного адреса функции гарантировано.*

## <a name="counting-semaphores"></a>Семафоры со счетчиком

ThreadX предоставляет 32-разрядные семафоры со счетчиком, значения которых находятся в диапазоне от 0 до 4 294 967 295. Существуют две операции для семафоров со счетчиком: *tx_semaphore_get* и *tx_semaphore_put*. Операция Get уменьшает значение семафора на один. Если значение семафора равно 0, то операция Get не выполняется. Обратная операции Get — операция Put.
Она увеличивает значение семафора на один.

Каждый семафор со счетчиком является общедоступным ресурсом. В ThreadX нет ограничений на использование семафоров со счетчиком.

Семафоры со счетчиком обычно используются для *взаимного исключения*. Однако семафоры со счетчиком можно также использовать для уведомления о событиях.

### <a name="mutual-exclusion"></a>Взаимное исключение

 Взаимное исключение применяется при управлении доступом потоков к определенным областям приложения (также называемым *критическими разделами* или *ресурсами приложения*). Если семафор используется для взаимного исключения, то его текущее значение равно общему числу потоков, которым разрешен доступ. В большинстве случаев семафоры со счетчиком, используемые для взаимного исключения, будут иметь начальное значение 1, то есть в каждый момент времени доступ к связанному ресурсу сможет получить только один поток. Семафоры со счетчиком, которые принимают только значение 0 или 1, обычно называются *двоичными семафорами*.

> [!IMPORTANT]
> *Если используется двоичный семафор, пользователь должен сделать так, чтобы поток не выполнял операцию Get с семафором, которым он уже владеет. Вторая операция Get завершится сбоем, что может привести к бессрочной приостановке вызывающего потока и постоянной недоступности ресурса.*

### <a name="event-notification"></a>Уведомление о событии

Семафоры со счетчиком можно также использовать для уведомления о событиях по схеме "производитель — получатель". Получатель пытается получить семафор со счетчиком, тогда как производитель увеличивает значение семафора при каждом обращении. Такие семафоры обычно имеют начальное значение 0, и их значение не увеличивается до тех пор, пока производитель не подготовит что-либо для получателя. Семафоры, используемые для уведомления о событиях, также могут использовать вызов службы ***tx_semaphore_ceiling_put***. Эта служба гарантирует, что значение семафора никогда не превысит значение, указанное в вызове.

### <a name="creating-counting-semaphores"></a>Создание семафоров со счетчиком

Семафоры со счетчиком создаются во время инициализации или во время выполнения потоками приложения. Начальное значение семафора задается во время создания. Число семафоров со счетчиком в приложении не ограничено.

### <a name="thread-suspension"></a>Приостановка потока

Потоки приложения могут быть приостановлены при попытке выполнить операцию Get с семафором, текущее значение которого равно 0.

После выполнения операции Put выполняется операция Get приостановленного потока и поток возобновляется. Если на одном семафоре со счетчиком приостанавливается несколько потоков, они возобновляются в том же порядке, в котором были приостановлены (FIFO).

Однако также возможно возобновление по приоритету, если приложение вызовет ***tx_semaphore_prioritize*** перед вызовом операции Put для семафора, которая прекращает приостановку потоков. Служба назначения приоритетов для семафора помещает поток с наибольшим приоритетом в начало списка приостановки, оставляя прочие приостановленные потоки в том же порядке по принципу FIFO.

### <a name="semaphore-put-notification"></a>Уведомление об операции Put с семафором

Некоторые приложения могут использовать преимущества уведомлений о каждой операции Put, выполняемой с семафором. ThreadX обеспечивает эту возможность с помощью службы ***tx_semaphore_put_notify***. Эта служба регистрирует указанную функцию уведомления приложения для заданного семафора. После чего ThreadX будет вызывать эту функцию уведомления приложения всякий раз, когда с семафором будет выполнена операция Put. Конкретная обработка в функции уведомления приложения определяется самим приложением. Однако обычно она включает в себя возобновление соответствующего потока для обработки нового события операции Put с семафором.

### <a name="semaphore-event-chainingtrade"></a>Цепочка событий семафора&trade;

Возможности уведомлений в ThreadX можно использовать для объединения различных событий синхронизации в цепочку. Обычно это удобно, когда один поток должен обрабатывать несколько событий синхронизации.

Например, вместо того чтобы приостанавливать отдельные потоки для сообщения очереди, флагов событий или семафора, приложение может зарегистрировать подпрограмму уведомления для каждого объекта. Тогда при вызове эта подпрограмма уведомления приложения сможет возобновить работу одного потока, который сможет опросить каждый объект, чтобы найти и обработать новое событие.

Как правило, *цепочки событий* позволяют уменьшить количество потоков, временные затраты и требования к ОЗУ. Они также предоставляют очень гибкий механизм для соблюдения требований синхронизации в более сложных системах.

### <a name="run-time-semaphore-performance-information"></a>Сведения о производительности семафоров во время выполнения

ThreadX предоставляет дополнительные сведения о производительности семафоров во время выполнения. Если при сборке приложения и библиотеки ThreadX был определен параметр **TX_SEMAPHORE_ENABLE_PERFORMANCE_INFO**, ThreadX собирает следующую информацию.

Общее число (для всей системы):

  - операций Put с семафорами;

  - операций Get с семафором;

  - приостановок из-за операций Get с семафором;

  - превышений времени ожидания операций Get с семафорами.

Общее число (для каждого семафора):

  - операций Put с семафорами;

  - операций Get с семафором;

  - приостановок из-за операций Get с семафором;

  - превышений времени ожидания операций Get с семафорами.

Эти сведения можно получить во время выполнения с помощью служб ***tx_semaphore_performance_info_get** _ и _*_tx_semaphore_performance_system_info_get_**. Сведения о производительности семафоров удобно использовать, чтобы определить, правильно ли работает приложение. Они также полезны для оптимизации приложения. Например, относительно частое превышение времени ожидания операций Get с семафором позволяет предположить, что другие потоки удерживают ресурсы слишком долго.

### <a name="semaphore-control-block-tx_semaphore"></a>TX_SEMAPHORE: блок управления семафора

Характеристики каждого семафора со счетчиком находятся в его блоке управления. Он содержит такие сведения, как текущее значение семафора. Эта структура определена в файле ***tx_api.h***.

Блоки управления семафора могут размещаться в любом месте в памяти, но чаще всего они определяются вне области какой-либо функции, благодаря чему функционируют как глобальная структура.

### <a name="deadly-embrace"></a>Взаимная блокировка

Одной из наиболее интересных и опасных проблем, связанных с семафорами, используемыми для взаимного исключения, является *взаимная блокировка*. Взаимная блокировка (или *взаимоблокировка*) — это ситуация, в которой два или более потоков бессрочно приостанавливаются при попытке получить семафоры, которые уже принадлежат им обоим.

Эту ситуацию лучше всего можно продемонстрировать на примере двух потоков и двух семафоров. Предположим, первый поток владеет первым семафором, а второй поток — вторым. Если первый поток пытается получить второй семафор и в то же время второй поток пытается получить первый, оба входят в состояние взаимоблокировки. Кроме того, если эти потоки бессрочно приостановлены, связанные с ними ресурсы также окончательно блокируются. Этот пример показан на рис. 8.

**Взаимная блокировка** (пример)

![Пример приостановленных потоков](./media/user-guide/example-suspended-threads.png)

**Рисунок 8. Пример приостановленных потоков**

Для систем реального времени взаимную блокировку можно предотвратить, наложив определенные ограничения на то, как потоки получают семафоры. В каждый момент времени потоки могут владеть только одним семафором. При этом они могут владеть несколькими семафорами, если собирают их значения в одном и том же порядке. Если в предыдущем примере первый и второй потоки будут получать первый и второй семафоры по порядку, взаимная блокировка будет предотвращена.

> [!TIP]
> *Для выхода из взаимной блокировки можно также использовать время ожидания приостановки, связанное с операцией Get.*

### <a name="priority-inversion"></a>Инверсия приоритета

Еще одной проблемой, связанной с взаимоисключающими семафорами, является инверсия приоритета. Эта тема более подробно рассмотрена в разделе [Проблемы, связанные с приоритетами потоков](#thread-priority-pitfalls).

Основная проблема возникает, когда поток с более низким приоритетом владеет семафором, требуемым потоку с более высоким приоритетом. Сама по себе эта ситуация является нормальной. Однако потоки с промежуточными приоритетами могут привести к инверсии приоритета на неопределенно долгий срок. Чтобы устранить эту проблему, можно тщательно выбирать приоритет потоков, использовать порог вытеснения и временно повышать приоритет потока, владеющего ресурсом, до уровня потока с более высоким приоритетом.

## <a name="mutexes"></a>Mutexes

Помимо семафоров ThreadX также предоставляет объект "мьютекс". Мьютекс по сути является двоичным семафором. Это значит, что в каждый момент времени мьютексом может владеть только один поток. Кроме того, один и тот же поток может успешно выполнить операцию Get с принадлежащим ему мьютексом несколько раз, а точнее — 4 294 967 295 раз. Существуют две операции с объектом "мьютекс": ***tx_mutex_get** _ и _*_tx_mutex_put_**. Операция Get позволяет получить мьютекс, не принадлежащий другому потоку, в то время как операция Put освобождает ранее полученный мьютекс. Чтобы поток освободил мьютекс, количество операций Put должно равняться числу предыдущих операций Get.

Каждый мьютекс является общедоступным ресурсом. В ThreadX нет ограничений на использование мьютексов.

Мьютексы ThreadX используются исключительно для *взаимного исключения*. В отличие от семафоров со счетчиком, мьютексы не используются для уведомления о событиях.

### <a name="mutex-mutual-exclusion"></a>Взаимное исключение мьютексов

Как уже было сказано в разделе о семафорах со счетчиком, взаимное исключение используется при управлении доступом потоков к определенным областям приложения (также называемым *критическими разделами* или *ресурсами приложения*). Если мьютекс ThreadX доступен, то его счетчик владения равен 0. После получения мьютекса потоком его счетчик владения увеличивается на единицу для каждой успешной операции Get, выполненной с мьютексом, и уменьшается для каждой успешной операции Put.

### <a name="creating-mutexes"></a>Создание мьютексов

Мьютексы ThreadX создаются во время инициализации или выполнения потоками приложения. Начальным состоянием мьютекса всегда является состояние доступности. При создании мьютекса можно также выбрать функцию *наследования приоритета*.

### <a name="thread-suspension"></a>Приостановка потока

Потоки приложения могут быть приостановлены при попытке выполнить операцию Get с мьютексом, уже принадлежащим другому потоку.

После того как поток-владелец выполнит то же количество операций Put, будет выполнена операция Get приостановленного потока, который получит мьютекс, и этот поток возобновится. Если на одном мьютексе приостанавливается несколько потоков, они возобновляются в том же порядке, в котором были приостановлены (FIFO).

Однако если во время создания мьютекса было выбрано наследование приоритета, возобновление автоматически выполняется по приоритету. Кроме того, возможно возобновление по приоритету, если приложение вызовет ***tx_mutex_prioritize*** перед вызовом операции Put с мьютексом, которая прекращает приостановку потоков. Служба назначения приоритетов для мьютекса помещает поток с наибольшим приоритетом в начало списка приостановки, оставляя прочие приостановленные потоки в том же порядке по принципу FIFO.

### <a name="run-time-mutex-performance-information"></a>Сведения о производительности мьютексов во время выполнения

ThreadX предоставляет дополнительные сведения о производительности мьютексов во время выполнения. Если при сборке приложения и библиотеки ThreadX был определен параметр **TX_MUTEX_ENABLE_PERFORMANCE_INFO**, ThreadX собирает следующую информацию.

Общее число (для всей системы):

- операций Put с мьютексом;

- операций Get с мьютексом;

- приостановок при выполнении операций Get с мьютексом;

- превышений времени ожидания при выполнении операций Get с мьютексом;

- инверсий приоритета из-за мьютекса;

- наследований приоритета по мьютексам.

Общее число (для каждого мьютекса):

  - операций Put с мьютексом;

  - операций Get с мьютексом;

  - приостановок при выполнении операций Get с мьютексом;

  - превышений времени ожидания при выполнении операций Get с мьютексом;

  - инверсий приоритета из-за мьютекса;

  - наследований приоритета по мьютексам.

Эти сведения можно получить во время выполнения с помощью служб ***tx_mutex_performance_info_get** _ и _*_tx_mutex_performance_system_info_get_*. Сведения о производительности мьютексов удобно использовать, чтобы определить, правильно ли работает приложение. Они также полезны для оптимизации приложения. Например, относительно частое превышение времени ожидания операций Get с мьютексом позволяет предположить, что другие потоки удерживают ресурсы слишком долго.

### <a name="mutex-control-block-tx_mutex"></a>TX_MUTEX: блок управления мьютекса

Характеристики каждого мьютекса находятся в его блоке управления. Он содержит такие сведения, как текущий счетчик владений мьютексом, а также указатель на поток, владеющий мьютексом. Эта структура определена в файле ***tx_api.h***. Блоки управления мьютекса могут размещаться в любом месте в памяти, но чаще всего они определяются вне области какой-либо функции, благодаря чему функционируют как глобальная структура.

### <a name="deadly-embrace"></a>Взаимная блокировка

Одной из наиболее интересных и опасных проблем, связанных с владением мьютексами, является *взаимная блокировка*. Взаимная блокировка (или *взаимоблокировка*) — это ситуация, в которой два или более потоков бессрочно приостанавливаются при попытке получить мьютекс, который принадлежит другим потокам. Особенности *взаимной блокировки*, а также способы ее предотвращения в полной мере относятся и к объекту "мьютекс".

### <a name="priority-inversion"></a>Инверсия приоритета

Как упоминалось ранее, основная проблема, связанная со взаимным исключением, — это инверсия приоритета. Эта тема более подробно рассмотрена в разделе [Проблемы, связанные с приоритетами потоков](#thread-priority-pitfalls).

Основная проблема возникает, когда поток с более низким приоритетом владеет семафором, требуемым потоку с более высоким приоритетом. Сама по себе эта ситуация является нормальной. Однако потоки с промежуточными приоритетами могут привести к инверсии приоритета на неопределенно долгий срок. В отличие от семафоров, рассмотренных ранее, объект "мьютекс" ThreadX позволяет использовать необязательное *наследование приоритета*. Основная идея наследования приоритета заключается в том, что приоритет потока с более низким приоритетом временно поднимается до уровня потока с более высоким приоритетом, которому нужен мьютекс, принадлежащий потоку с более низким приоритетом. Когда поток с более низким приоритетом освобождает мьютекс, его исходный приоритет восстанавливается и поток с более высоким приоритетом получает мьютекс. Эта функция устраняет недетерминированную инверсию приоритета, сводя время инверсии ко времени, в течение которого поток с более низким приоритетом удерживает мьютекс. Разумеется, методики устранения недетерминированной инверсии приоритета, описанные ранее в этой главе, также действенны и для мьютексов.

## <a name="event-flags"></a>Флаги событий

Флаги событий предоставляют мощный инструмент для синхронизации потоков. Каждый флаг события представлен одним битом. Флаги событий упорядочены в группы по 32 флага. Потоки могут обрабатывать все 32 флага событий в группе одновременно. Для задания событий используется служба ***tx_event_flags_set** _, а для получения — служба _*_tx_event_flags_get_**.

Установка флагов событий выполняется с помощью логической операции "И" или "ИЛИ" с текущими флагами событий и новыми флагами событий. Тип логической операции ("И" или "ИЛИ") задается в вызове ***tx_event_flags_set***.

Аналогичные логические операции применяются для получения флагов событий. Запрос Get может указывать, что требуются все указанные флаги событий (логическое "И").

Кроме того, запрос Get может указывать, что соответствовать запросу будет любой из указанных флагов событий (логическое "ИЛИ"). Тип логической операции для получения флагов событий указывается в вызове ***tx_event_flags_get***.

> [!IMPORTANT]
> *Флаги событий, которые соответствуют запросу Get, расходуются, т. е. им присваивается значение 0, если в запросе указан параметр* **TX_OR_CLEAR** *или* **TX_AND_CLEAR** *.*

Каждая группа флагов событий является общедоступным ресурсом. В ThreadX нет ограничений на использование групп флагов событий.

### <a name="creating-event-flags-groups"></a>Создание групп флагов событий

Группы флагов событий создаются во время инициализации или во время выполнения потоками приложения. Во время создания все флаги событий в группе имеют значение 0. Количество групп флагов событий в приложении не ограничено.

### <a name="thread-suspension"></a>Приостановка потока

Потоки приложения могут быть приостановлены при попытке получить какое-либо логическое сочетание флагов событий из группы. После установки флага события проверяются запросы Get всех приостановленных потоков. Все потоки, у которых уже имеются необходимые флаги событий, возобновляются.

> [!NOTE]
> *Все приостановленные потоки в группе флагов событий проверяются при установке флагов событий. Это, конечно, приводит к дополнительным издержкам. Поэтому рекомендуется ограничить количество потоков, использующих одну группу флагов событий, до разумных пределов.*

### <a name="event-flags-set-notification"></a>Уведомление об установке флагов событий

Некоторые приложения могут использовать преимущества уведомлений о каждой установке флага события. ThreadX обеспечивает эту возможность с помощью службы ***tx_event_flags_set_notify***. Эта служба регистрирует указанную функцию уведомления приложения для заданной группы флагов событий. После чего ThreadX будет вызывать эту функцию уведомления приложения всякий раз, когда в группе будет установлен флаг события. Конкретная обработка в функции уведомления приложения определяется самим приложением. Однако обычно она включает в себя возобновление соответствующего потока для обработки нового флага события.

### <a name="event-flags-event-chainingtrade"></a>Event-chaining&trade; для флагов событий

Возможности уведомлений в ThreadX можно использовать для объединения различных событий синхронизации в цепочку. Обычно это удобно, когда один поток должен обрабатывать несколько событий синхронизации.

Например, вместо того чтобы приостанавливать отдельные потоки для сообщения очереди, флагов событий или семафора, приложение может зарегистрировать подпрограмму уведомления для каждого объекта. Тогда при вызове эта подпрограмма уведомления приложения сможет возобновить работу одного потока, который сможет опросить каждый объект, чтобы найти и обработать новое событие.

Как правило, *цепочки событий* позволяют уменьшить количество потоков, временные затраты и требования к ОЗУ. Они также предоставляют очень гибкий механизм для соблюдения требований синхронизации в более сложных системах.

### <a name="run-time-event-flags-performance-information"></a>Сведения о производительности флагов событий во время выполнения

ThreadX предоставляет дополнительные сведения о производительности флагов событий во время выполнения. Если при сборке приложения и библиотеки ThreadX был определен параметр **TX_EVENT_FLAGS_ENABLE_PERFORMANCE_INFO**, ThreadX собирает следующую информацию.

Общее число (для всей системы):

  - установок флагов событий;

  - получений флагов событий;

  - приостановок из-за получения флагов событий;

  - превышений времени ожидания получения флагов событий.

Общее число (для каждой группы флагов событий):

  - установок флагов событий;

  - получений флагов событий;

  - приостановок из-за получения флагов событий;

  - превышений времени ожидания получения флагов событий.

Эти сведения можно получить во время выполнения с помощью служб ***tx_event_flags_performance_info_get** _ и _*_tx_event_flags_performance_system_info_get_*_. С помощью сведений о производительности флагов событий удобно определять, правильно ли работает приложение. Они также полезны для оптимизации приложения. Например, относительно частое превышение времени ожидания для службы _ *_tx_event_flags_get_** позволяет предположить, что задано слишком короткое время ожидания приостановки для флагов событий.

### <a name="event-flags-group-control-block-tx_event_flags_group"></a>TX_EVENT_FLAGS_GROUP: блок управления группы флагов событий

Характеристики каждой группы флагов событий находятся в ее блоке управления. Он содержит такие сведения, как текущие параметры флагов событий и количество потоков, приостановленных для событий. Эта структура определена в файле ***tx_api.h***.

Блоки управления группы событий могут размещаться в любом месте в памяти, но чаще всего они определяются вне области какой-либо функции, благодаря чему функционируют как глобальная структура.

### <a name="memory-block-pools"></a>Пулы блоков памяти

Быстрое и детерминированное выделение памяти — вечная проблема в приложениях реального времени. Ввиду этого ThreadX предоставляет возможность создать и администрировать несколько пулов блоков памяти фиксированного размера.

Так как пулы блоков памяти состоят из блоков фиксированного размера, проблемы фрагментации никогда не возникают. Конечно, фрагментация приводит к поведению, которое, по сути, является недетерминированным. Кроме того, время, затрачиваемое на выделение и освобождение блока памяти фиксированного размера, сравнимо с простым управлением с помощью связанного списка. Более того, выделение и освобождение блока памяти выполняется на уровне заголовка списка доступных ресурсов. Это обеспечивает самую быструю обработку связанного списка и позволяет хранить наиболее востребованный блок памяти в кэше.

Отсутствие гибкости — основной недостаток пулов блоков памяти фиксированного размера. Размер блока пула должен быть достаточно большим, чтобы выполнять требования к памяти для пользователей в наиболее пессимистичных сценариях. Разумеется, память может расходоваться впустую, если к одному пулу отправляется много запросов на память разного размера. Возможное решение — создание нескольких пулов блоков памяти, содержащих блоки памяти разного размера.

Каждый пул блоков памяти является общедоступным ресурсом. В ThreadX нет ограничений на использование пулов.

### <a name="creating-memory-block-pools"></a>Создание пулов блоков памяти

Пулы блоков памяти создаются во время инициализации или во время выполнения потоками приложения. Количество пулов блоков памяти в приложении не ограничено.

### <a name="memory-block-size"></a>Размер блока памяти

Как упоминалось ранее, пулы блоков памяти содержат несколько блоков фиксированного размера. Размер блока в байтах указывается во время создания пула.

> [!NOTE]
> *ThreadX добавляет к каждому блоку памяти в пуле небольшой объем служебных данных (размер указателя C). Кроме того, ThreadX может заполнять блок, чтобы сохранить его размер для выравнивания начала каждого блока памяти.*

### <a name="pool-capacity"></a>Емкость пула

Количество блоков памяти в пуле зависит от размера блока и общего числа байтов в области памяти, указанной во время создания. Емкость пула вычисляется путем деления размера блока (с учетом заполнения и байтов служебных данных указателей) на общее число байтов в указанной области памяти.

### <a name="pools-memory-area"></a>Область памяти пула

Как упоминалось ранее, область памяти пула блоков указывается во время создания. Как и в случае с другими областями памяти в ThreadX, она может находиться в любом месте адресного пространства целевого оборудования.

Это важная функция ввиду значительной гибкости, которую она обеспечивает. Например, предположим, что у продукта взаимодействия имеется высокоскоростная область памяти для операций ввода-вывода. Этой областью памяти будет легко управлять, если создать в ней пул блоков памяти ThreadX.

### <a name="thread-suspension"></a>Приостановка потока

Потоки приложения могут быть приостановлены при ожидании блока памяти из пустого пула. Когда блок возвращается в пул, приостановленный поток получает этот блок и возобновляет выполнение.

Если на одном пуле блоков памяти приостанавливается несколько потоков, они возобновляются в том же порядке, в котором были приостановлены (FIFO).

Однако также возможно возобновление по приоритету, если приложение вызовет ***tx_block_pool_prioritize*** перед вызовом освобождения блока, который прекращает приостановку потоков. Служба назначения приоритетов для пула блоков помещает поток с наибольшим приоритетом в начало списка приостановки, оставляя прочие приостановленные потоки в том же порядке по принципу FIFO.

### <a name="run-time-block-pool-performance-information"></a>Сведения о производительности пула блоков во время выполнения

ThreadX предоставляет дополнительные сведения о производительности пула блоков во время выполнения. Если при сборке приложения и библиотеки ThreadX был определен параметр **TX_BLOCK_POOL_ENABLE_PERFORMANCE_INFO**, ThreadX собирает следующую информацию.

Общее число (для всей системы):

  - выделенных блоков;

  - освобожденных блоков;

  - приостановок из-за выделения;

  - превышений времени ожидания выделения.

Общее число (для каждого пула блоков):

  - выделенных блоков;

  - освобожденных блоков;

  - приостановок из-за выделения;

  - превышений времени ожидания выделения.

Эти сведения можно получить во время выполнения с помощью служб ***tx_block_pool_performance_info_get** _ и _*_tx_block_pool_performance_system_info_get_**. Сведения о производительности пулов блоков удобно использовать, чтобы определить, правильно ли работает приложение. Они также полезны для оптимизации приложения. Например, относительно частая приостановка из-за выделения блоков может означать, что пул блоков слишком мал.

### <a name="memory-block-pool-control-block-tx_block_pool"></a>TX_BLOCK_POOL: блок управления пула блоков памяти

Характеристики каждого пула блоков памяти находятся в его блоке управления. Он содержит такие сведения, как количество доступных блоков памяти и размер блока памяти в пуле. Эта структура определена в файле ***tx_api.h***.

Блоки управления пула могут размещаться в любом месте в памяти, но чаще всего они определяются вне области какой-либо функции, благодаря чему функционируют как глобальная структура.

### <a name="overwriting-memory-blocks"></a>Перезапись блоков памяти

Важно убедиться, чтобы пользователь выделенного блока памяти не выполнял запись за его пределами. В противном случае происходит повреждение соседней (обычно следующей) области памяти. Результаты непредсказуемы и часто являются неустранимыми для приложения.

## <a name="memory-byte-pools"></a>Пулы байтов памяти

Пулы байтов памяти ThreadX похожи на стандартные кучи C. В отличие от стандартной кучи C, можно использовать несколько пулов байтов памяти. Кроме того, потоки могут быть приостановлены на пуле до тех пор, пока не будет доступен запрошенный объем памяти.

Выделение памяти из пулов байтов памяти похоже на традиционные вызовы ***malloc** _, которые содержат требуемый объем памяти (в байтах). Память выделяется из пула по принципу _first-fit* (первый подходящий), т. е. используется первый свободный блок памяти, соответствующий запросу. Избыточная память из этого блока преобразовывается в новый блок и возвращается в список свободной памяти. Этот процесс называется *фрагментацией*.

Смежные свободные блоки памяти *объединяются* вместе при последующем поиске для выделения свободного блока памяти достаточно большого объема. Этот процесс называется *дефрагментацией*.

Каждый пул байтов памяти является общедоступным ресурсом. В ThreadX нет ограничений на использование пулов, за исключением того, что службы управления байтами памяти невозможно вызывать из подпрограмм ISR.

### <a name="creating-memory-byte-pools"></a>Создание пулов байтов памяти

Пулы байтов памяти создаются во время инициализации или во время выполнения потоками приложения. Количество пулов байтов памяти в приложении не ограничено.

### <a name="pool-capacity"></a>Емкость пула

Число доступных для выделения байтов в пуле байтов памяти немного меньше значения, указанного во время создания. Это связано с тем, что для управления областью свободной памяти используются служебные данные. Каждый свободный блок памяти в пуле требует служебных данных, необходимых для хранения двух указателей C. Кроме того, пул создается с двумя блоками: большим свободным блоком и небольшим постоянным блоком, выделенным в конце области памяти. Этот выделенный блок используется для повышения производительности алгоритма выделения. Он устраняет необходимость постоянно проверять конец области пула во время объединения.

Во время выполнения объем служебных данных в пуле обычно увеличивается. При выделении блоков с нечетным числом байтов они заполняются, чтобы обеспечить правильное выравнивание следующего блока памяти. Кроме того, объем служебных данных увеличивается по мере того, как пул становится более фрагментированным.

### <a name="pools-memory-area"></a>Область памяти пула

Область памяти для пула байтов памяти задается во время его создания. Как и в случае с другими областями памяти в ThreadX, она может находиться в любом месте адресного пространства целевого оборудования. Это важная функция ввиду значительной гибкости, которую она обеспечивает. Например, если целевое оборудование оснащено областями высокоскоростной и низкоскоростной памяти, то пользователь может управлять выделением памяти в обеих этих областях, создавая пулы в каждой из них.

### <a name="thread-suspension"></a>Приостановка потока

Потоки приложения могут быть приостановлены при ожидании байтов памяти из пула. Когда становится доступна достаточно большая непрерывная область памяти, она выделяется приостановленным потокам, которые ее запросили, и они возобновляются.

Если на одном пуле байтов памяти приостанавливается несколько потоков, они получают память (возобновляются) в том же порядке, в котором были приостановлены (FIFO).

Однако также возможно возобновление по приоритету, если приложение вызовет ***tx_byte_pool_prioritize*** перед вызовом освобождения байтов, который прекращает приостановку потоков. Служба назначения приоритетов для пула байтов помещает поток с наибольшим приоритетом в начало списка приостановки, оставляя прочие приостановленные потоки в том же порядке по принципу FIFO.

### <a name="run-time-byte-pool-performance-information"></a>Сведения о производительности пула байтов во время выполнения

ThreadX предоставляет дополнительные сведения о производительности пула байтов во время выполнения. Если при сборке приложения и библиотеки ThreadX был определен параметр ***TX_BYTE_POOL_ENABLE_PERFORMANCE_INFO***, ThreadX собирает следующую информацию.

Общее число (для всей системы):

  - выделений памяти;

  - выпуски

  - искомых фрагментов;

  - объединенных фрагментов;

  - созданных фрагментов;

  - приостановок из-за выделения;

  - превышений времени ожидания выделения.

Общее число (для каждого пула байтов):

  - выделений памяти;

  - выпуски

  - искомых фрагментов;

  - объединенных фрагментов;

  - созданных фрагментов;

  - приостановок из-за выделения;

  - превышений времени ожидания выделения.

Эти сведения можно получить во время выполнения с помощью служб **tx_byte_pool_performance_info_get** и _tx_byte_pool_performance_system_info_get_. Сведения о производительности пулов байтов удобно использовать, чтобы определить, правильно ли работает приложение. Они также полезны для оптимизации приложения. Например, относительно частая приостановка из-за выделения памяти может означать, что пул байтов слишком мал.

### <a name="memory-byte-pool-control-block-tx_byte_pool"></a>TX_BYTE_POOL: блок управления пула байтов памяти

Характеристики каждого пула байтов памяти находятся в его блоке управления. Он содержит полезную информацию, например количество доступных байтов в пуле. Эта структура определена в файле ***tx_api.h***.

Блоки управления пула могут размещаться в любом месте в памяти, но чаще всего они определяются вне области какой-либо функции, благодаря чему функционируют как глобальная структура.

### <a name="nondeterministic-behavior"></a>Недетерминированное поведение

Хотя пулы байтов памяти обеспечивают наиболее гибкое выделение памяти, они также могут быть подвержены недетерминированному поведению. Например, пул байтов памяти может содержать 2000 байт доступной памяти, но не соответствовать запросу на выделение 1000 байт. Это связано с тем, что количество расположенных подряд свободных байтов не гарантируется. Даже если существует свободный блок размером в 1000 байт, не гарантируется время его поиска. Вполне возможно, что для поиска блока в 1000 байт потребуется выполнить поиск по всему пулу памяти.

> [!TIP]
> *В результате недетерминированного поведения пулов байтов памяти, как правило, рекомендуется избегать использования служб байтов памяти в тех областях, где требуется детерминированное поведение в реальном времени. Многие приложения предварительно распределяют требуемую память во время инициализации или настройки времени выполнения.*

### <a name="overwriting-memory-blocks"></a>Перезапись блоков памяти

Важно проследить, чтобы пользователь выделенной памяти не выполнял запись за ее пределами. В противном случае происходит повреждение соседней (обычно следующей) области памяти. Результаты непредсказуемы и часто могут приводить к неустранимым последствиям при выполнении программы.

## <a name="application-timers"></a>Таймеры приложения

Быстрое реагирование на асинхронные внешние события является самой важной функцией внедренных приложений реального времени. Однако многие из этих приложений должны также выполнять определенные действия через предопределенные интервалы времени.

Таймеры приложения ThreadX дают приложениям возможность выполнять функции приложения C через определенные интервалы времени. Таймер приложения также может истекать только один раз. Этот тип таймера называется *одноразовым*, а таймеры с повторяющимся интервалом называются *периодическими*.

Каждый таймер приложения является общедоступным ресурсом. В ThreadX нет ограничений на использование таймеров приложения.

### <a name="timer-intervals"></a>Интервалы таймера

В ThreadX интервалы времени измеряются периодическими прерываниями таймера. Каждое прерывание таймера называется его *тактом*. Фактическое время между тактами таймера задается приложением, но для большинства реализаций нормой является 10 мс. Конфигурация периодического таймера обычно находится в файле сборки ***tx_initialize_low_level***.

Стоит упомянуть, что для функционирования таймеров приложения базовое оборудование должно иметь возможность создавать периодические прерывания. В некоторых случаях процессор имеет встроенную функцию периодических прерываний. Если в процессоре нет такой функции, на плате пользователя должно быть периферийное устройство, которое может создавать периодические прерывания.

> [!IMPORTANT]
> *ThreadX может работать даже без источника периодических прерываний. Однако в этом случае вся обработка, связанная с таймерами, отключается. Это касается временных срезов, времени ожидания приостановки и служб таймеров.*

### <a name="timer-accuracy"></a>Точность таймера

Срок действия таймеров задается в тактах. Указанное значение срока действия уменьшается на единицу на каждом такте таймера. Так как таймер приложения может быть включен непосредственно перед прерыванием (или тактом) таймера, его фактический срок действия может быть меньше на один такт.

Если частота тактов таймера равна 10 мс, то срок действия таймера приложения может истечь на 10 мс раньше. Это более важно для таймеров с тактом в 10 мс, чем для таймеров с тактом в 1 с. Разумеется, увеличение частоты прерываний таймера уменьшает эту погрешность.

### <a name="timer-execution"></a>Выполнение таймера

Таймеры приложения выполняются в том порядке, в котором они становятся активными. Например, если были созданы три таймера с одинаковым значением срока действия и они были активированы, то их соответствующие функции срока действия гарантированно будут выполняться в порядке активации.

### <a name="creating-application-timers"></a>Создание таймеров приложения

Таймеры приложения создаются во время инициализации или во время выполнения потоками приложения. Количество таймеров приложения в приложении не ограничено.

### <a name="run-time-application-timer-performance-information"></a>Сведения о производительности таймера приложения во время выполнения

ThreadX предоставляет дополнительные сведения о производительности таймеров приложения во время выполнения. Если при сборке библиотеки и приложения ThreadX был определен параметр **TX_TIMER_ENABLE_PERFORMANCE_INFO**, ThreadX собирает следующую информацию.

Общее число (для всей системы):

- активаций;

- деактиваций;

- повторных активаций (периодические таймеры);

- expirations

- корректировок срока действия.

Общее число (для каждого таймера приложения):

- активаций;

- деактиваций;

- повторных активаций (периодические таймеры);

- expirations

- корректировок срока действия.

Эти сведения можно получить во время выполнения с помощью служб ***tx_timer_performance_info_get** _ и _*_tx_timer_performance_system_info_get_**. Сведения о производительности таймеров приложения удобно использовать, чтобы определить, правильно ли работает приложение. Они также полезны для оптимизации приложения.

### <a name="application-timer-control-block-tx_timer"></a>TX_TIMER: блок управления таймера приложения

Характеристики каждого таймера приложения находятся в его блоке управления. Он содержит полезную информацию, например 32-разрядное обозначение срока действия. Эта структура определена в файле ***tx_api.h***.

Блоки управления таймера приложения могут размещаться в любом месте в памяти, но чаще всего они определяются вне области какой-либо функции, благодаря чему функционируют как глобальная структура.

### <a name="excessive-timers"></a>Избыточные таймеры

По умолчанию таймеры приложения выполняются в скрытом системном потоке, который запускается с нулевым приоритетом, что обычно выше приоритета любого потока приложения. Поэтому обработка внутри таймеров приложения должна быть минимальной.

Важно также по возможности избегать использования таймеров, срок действия которых истекает на каждом такте таймера. Такая ситуация может привести к генерированию чрезмерного количества служебных данных в приложении.

> [!IMPORTANT]
> *Как упоминалось ранее, таймеры приложения выполняются из скрытого системного потока. Поэтому важно не указывать приостановку каких-либо вызовов службы ThreadX, выполняемых в функции срока действия таймера приложения.*

## <a name="relative-time"></a>Относительное время

В дополнение к ранее упомянутым таймерам приложения ThreadX предоставляет один постоянно увеличивающийся 32-разрядный счетчик тактов. Значение счетчика тактов, или *времени*, увеличивается на единицу при каждом прерывании таймера.

Приложение может считывать или устанавливать этот 32-разрядный счетчик с помощью вызовов ***tx_time_get** _ и _*_tx_time_set_** соответственно. Использование этого счетчика тактов полностью определяется приложением. Он не используется внутри ThreadX.

## <a name="interrupts"></a>Прерывания

Быстрое реагирование на асинхронные события — фундаментальная функция внедренных приложений реального времени. Приложение узнает о таком событии с помощью аппаратных прерываний.

Прерывание является асинхронным изменением в работе процессора. Как правило, когда происходит прерывание, процессор *прерываний* сохраняет небольшую часть текущей операции в стеке и передает управление соответствующему вектору прерывания. Вектор прерывания — это, собственно, адрес подпрограммы, отвечающей за обработку конкретного типа прерывания. Точная процедура обработки прерываний зависит от конкретного процессора.

### <a name="interrupt-control"></a>Управление прерываниями

Служба ***tx_interrupt_control*** позволяет приложениям включать и отключать прерывания. Эта служба возвращает предыдущее состояние включения или отключения прерываний. Важно упомянуть, что управление прерываниями влияет только на сегмент программы, выполняемый в данный момент. Например, если поток отключает прерывания, то они остаются отключенными только во время выполнения этого потока.

> [!NOTE]
> *Немаскируемое прерывание (NMI) — это прерывание, которое не может быть отключено оборудованием. Такое прерывание может использоваться приложениями ThreadX. Однако подпрограмме обработки NMI приложения запрещено использовать управление контекстом и какие-либо службы API в ThreadX.*

### <a name="threadx-managed-interrupts"></a>Управляемые прерывания ThreadX

ThreadX предоставляет приложениям полное управление прерываниями. Это включает в себя сохранение и восстановление контекста прерванного выполнения. Кроме того, ThreadX позволяет вызывать определенные службы из подпрограмм обработки прерываний (ISR). Ниже приведен список служб ThreadX, которые можно запускать из подпрограмм ISR.

```c
tx_block_allocate
tx_block_pool_info_get tx_block_pool_prioritize
tx_block_pool_performance_info_get
tx_block_pool_performance_system_info_get tx_block_release
tx_byte_pool_info_get tx_byte_pool_performance_info_get
tx_byte_pool_performance_system_info_get
tx_byte_pool_prioritize tx_event_flags_info_get
tx_event_flags_get tx_event_flags_set
tx_event_flags_performance_info_get
tx_event_flags_performance_system_info_get
tx_event_flags_set_notify tx_interrupt_control
tx_mutex_performance_info_get
tx_mutex_performance_system_info_get tx_queue_front_send
tx_queue_info_get tx_queue_performance_info_get
tx_queue_performance_system_info_get tx_queue_prioritize
tx_queue_receive tx_queue_send tx_semaphore_get
tx_queue_send_notify tx_semaphore_ceiling_put
tx_semaphore_info_get tx_semaphore_performance_info_get
tx_semaphore_performance_system_info_get
tx_semaphore_prioritize tx_semaphore_put tx_thread_identify
tx_semaphore_put_notify tx_thread_entry_exit_notify
tx_thread_info_get tx_thread_resume
tx_thread_performance_info_get
tx_thread_performance_system_info_get
tx_thread_stack_error_notify tx_thread_wait_abort tx_time_get
tx_time_set tx_timer_activate tx_timer_change
tx_timer_deactivate tx_timer_info_get
tx_timer_performance_info_get
tx_timer_performance_system_info_get
```

> [!IMPORTANT]
> *Приостановка из подпрограмм ISR запрещена. Следовательно, параметр **wait_option** для всех вызовов служб ThreadX, выполняемых из ISR, должен иметь значение **TX_NO_WAIT**.*

### <a name="isr-template"></a>Шаблон ISR

Для управления прерываниями приложения в начале и в конце подпрограмм ISR этого приложения следует вызывать несколько служебных программ ThreadX. Формат обработки прерываний зависит от используемых портов.

Ниже приведен небольшой сегмент кода, типичный для большинства управляемых подпрограмм ISR в ThreadX. В большинстве случаев эта обработка выполняется на языке ассемблера.

```c
_application_ISR_vector_entry:

; Save context and prepare for

; ThreadX use by calling the ISR

; entry function.

CALL _tx_thread_context_save

; The ISR can now call ThreadX

; services and its own C functions

; When the ISR is finished, context

; is restored (or thread preemption)

; by calling the context restore ; function. Control does not return!

JUMP _tx_thread_context_restore
```

### <a name="high-frequency-interrupts"></a>Высокочастотные прерывания

Некоторые прерывания происходят с такой высокой частотой, что сохранение и восстановление полного контекста при каждом прерывании требует чрезмерной пропускной способности для обработки. В таких случаях для приложения обычно используется небольшая подпрограмма ISR на языке ассемблера, которая выполняет ограниченную обработку большинства этих высокочастотных прерываний.

В какой-то момент времени этой небольшой подпрограмме ISR может потребоваться взаимодействовать с ThreadX. Для этого вызываются функции входа и выхода, описанные в приведенном выше шаблоне.

### <a name="interrupt-latency"></a>Задержка прерываний

ThreadX блокирует прерывания на короткий период времени. Максимальный период отключения прерываний зависит от времени, необходимого для сохранения или восстановления контекста потока.
